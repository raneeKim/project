{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba74de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    여러 CSV 파일을 로드하여 데이터를 불러옵니다.\n",
    "    \"\"\"\n",
    "    # 재무제표 정보 로드\n",
    "    comp_finance_train = pd.read_csv('재무제표정보_train.csv')\n",
    "    comp_finance_test = pd.read_csv('재무제표정보_test.csv')\n",
    "    comp_finance = pd.concat([comp_finance_train, comp_finance_test])\n",
    "    \n",
    "    # 기업 정보 로드\n",
    "    comp_intro_train = pd.read_csv('기업정보요약_train.csv')\n",
    "    comp_intro_test = pd.read_csv('기업정보요약_test.csv')\n",
    "    comp_intro = pd.concat([comp_intro_train, comp_intro_test])\n",
    "    \n",
    "    # 실제 사업자번호 로드\n",
    "    mapping = pd.read_csv('mapping_info.csv')\n",
    "    \n",
    "    comp_info_spe = pd.read_csv('기업정보상세.csv')\n",
    "    \n",
    "    # 산업분류코드 로드\n",
    "    df_industry = pd.read_excel('한국표준산업분류표.xlsx', index_col=1).reset_index().fillna(method='ffill')\n",
    "    \n",
    "    # 2022년 예측값을 위한 데이터 로드\n",
    "    df_predict_ex = pd.read_csv('predict_ex.csv', index_col=0)\n",
    "    \n",
    "    return comp_finance, comp_intro, mapping, df_industry, df_predict_ex\n",
    "\n",
    "def preprocess_industry(df_industry):\n",
    "    \"\"\"\n",
    "    산업분류코드를 전처리하고 필요한 칼럼만 추출합니다.\n",
    "    \"\"\"\n",
    "    def namee(row):\n",
    "        # 항목명 전처리\n",
    "        return row.split('(')[0]\n",
    "    \n",
    "    def dot_split(row):\n",
    "        # 소수점 제거\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return str(row).split('.')[0]\n",
    "    \n",
    "    def spe_industry(row):\n",
    "        # 중분류코드 전처리\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        elif len(str(row)) == 1:\n",
    "            return '0' + str(row)\n",
    "        else:\n",
    "            return str(row)\n",
    "    \n",
    "    # 항목명과 중분류코드 전처리 적용\n",
    "    df_industry['항목명'] = df_industry['항목명'].apply(namee)\n",
    "    df_industry['중분류코드_str'] = df_industry['중분류코드'].apply(dot_split).apply(spe_industry)\n",
    "    \n",
    "    # 필요한 칼럼만 추출 및 중복 제거\n",
    "    return df_industry[['대분류코드', '항목명', '중분류코드_str']].drop_duplicates()\n",
    "\n",
    "def preprocess_comp_intro(comp_intro, df_industry_unique):\n",
    "    \"\"\"\n",
    "    기업 정보 요약을 전처리하고 산업분류코드와 병합합니다.\n",
    "    \"\"\"\n",
    "    def dot_split(row):\n",
    "        # 소수점 제거\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return str(row).split('.')[0]\n",
    "    \n",
    "    def spe_industry2(row):\n",
    "        # 세세분류코드 전처리\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        elif len(str(row)) == 4:\n",
    "            return '0' + str(row)\n",
    "        else:\n",
    "            return str(row)\n",
    "    \n",
    "    def indCd1(row):\n",
    "        # 중분류코드 추출\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return row[0:2]\n",
    "    \n",
    "    # 세세분류코드 전처리\n",
    "    comp_intro['indCd1_str'] = comp_intro['indCd1'].apply(dot_split).apply(spe_industry2)\n",
    "    comp_intro['중분류코드_str'] = comp_intro['indCd1_str'].apply(indCd1)\n",
    "    \n",
    "    # 중분류코드를 기준으로 기업정보에 대분류코드와 항목명을 병합\n",
    "    comp_intro_m1 = pd.merge(comp_intro, df_industry_unique, on='중분류코드_str', how='left')\n",
    "    comp_intro_m1 = pd.merge(comp_intro_m1,comp_info_spe, left_on='BusinessNum', right_on='사업자등록번호', how='inner')\n",
    "    \n",
    "    return comp_intro_m1\n",
    "\n",
    "def preprocess_comp_intro_details(comp_intro_m1, mapping):\n",
    "    \"\"\"\n",
    "    기업 정보와 매핑 정보를 병합하고 주소, 설립일 등을 전처리합니다.\n",
    "    \"\"\"\n",
    "    # 마스킹된 BusinessNum을 기준으로 병합\n",
    "    df = pd.merge(comp_intro_m1, mapping, left_on='BusinessNum', right_on='사업자등록번호_마스킹', how='inner')\n",
    "    \n",
    "    # 필요한 컬럼만 추출\n",
    "    df2 = df[['BusinessNum', '설립일', '주소', '종업원수', '종업원수기준년월']]\n",
    "    \n",
    "    # 주소 전처리\n",
    "    df2['주소1'] = df2['주소'].apply(lambda x: str(x).split(' ')[0])\n",
    "    address_mapping = {\n",
    "        '서울특별시': '서울', '경기도': '경기', '경상북도': '경북', '경상남도': '경남',\n",
    "        '전라북도': '전북', '전라남도': '전남', '충청북도': '충북', '충청남도': '충남',\n",
    "        '인천광역시': '인천', '대구광역시': '대구', '부산광역시': '부산', '대전광역시': '대전',\n",
    "        '광주광역시': '광주', '울산광역시': '울산', '강원도': '강원', '세종특별자치시': '세종',\n",
    "        '제주특별자치도': '제주', '제주도': '제주'\n",
    "    }\n",
    "    df2['주소1'] = df2['주소1'].map(address_mapping).fillna(df2['주소1'])\n",
    "    \n",
    "    # 설립일 전처리\n",
    "    df2['설립일_dt'] = df2['설립일'].apply(lambda x: datetime.strptime(str(int(x)), '%Y%m%d') if x == x else None)\n",
    "    df2['설립연도'] = df2['설립일_dt'].dt.year\n",
    "    df2['연차'] = df2['설립연도'].apply(lambda x: '30년이상' if x and (2024 - x) >= 30 else (2024 - x) if x else None)\n",
    "    \n",
    "    # 종업원수 전처리\n",
    "    df2['종업원수기준년월_dt'] = df2['종업원수기준년월'].apply(lambda x: datetime.strptime(str(int(x)), '%Y%m') if x == x else None)\n",
    "    df2['종업원수기준년'] = df2['종업원수기준년월_dt'].dt.year\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def fill_missing_employee_counts(df2, comp_finance):\n",
    "    \"\"\"\n",
    "    결측치가 있는 종업원수를 인건비를 통해 보완하고 이상치를 제거합니다.\n",
    "    \"\"\"\n",
    "    # 최대 연도와 인건비 추출\n",
    "    df3 = comp_finance.groupby('BusinessNum').agg({'stYear': 'max', '인건비': 'first'}).reset_index()\n",
    "    df2 = df2.merge(df3, on='BusinessNum', how='left')\n",
    "    \n",
    "    def remove_outliers(group):\n",
    "        \"\"\"\n",
    "        IQR 방식을 사용하여 이상치 제거\n",
    "        \"\"\"\n",
    "        Q1 = group.quantile(0.25)\n",
    "        Q3 = group.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        return (group >= lower_bound) & (group <= upper_bound)\n",
    "    \n",
    "    def filter_outliers(group):\n",
    "        \"\"\"\n",
    "        그룹별로 이상치 제거\n",
    "        \"\"\"\n",
    "        return group[remove_outliers(group['종업원수']) & remove_outliers(group['인건비'])]\n",
    "    \n",
    "    # 이상치 제거\n",
    "    df_cleaned = df2.groupby('연차').apply(filter_outliers).reset_index(drop=True)\n",
    "    \n",
    "    # 연차별 평균 계산\n",
    "    df_mean = df_cleaned.pivot_table(index='연차', values=['인건비', '종업원수'], aggfunc='mean').reset_index()\n",
    "    df_mean.columns = ['연차', '평균인건비', '평균종업원수']\n",
    "    \n",
    "    # 결측치 보완\n",
    "    df4 = df2.merge(df_mean, on='연차', how='left')\n",
    "    df4['인건비'] = df4['인건비'].fillna(df4['평균인건비'])\n",
    "    df4['종업원수'] = df4['종업원수'].fillna(df4['평균종업원수'])\n",
    "    \n",
    "    return df4\n",
    "\n",
    "def categorize_data(df):\n",
    "    \"\"\"\n",
    "    연차와 주소를 범주화하여 새로운 컬럼을 생성합니다.\n",
    "    \"\"\"\n",
    "    def convert_years(row):\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        elif row == '30년이상':\n",
    "            return 30.0\n",
    "        else:\n",
    "            return float(row)\n",
    "    \n",
    "    def convert_years_2(row):\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        elif row <= 5:\n",
    "            return '5년이하'\n",
    "        elif row <= 10:\n",
    "            return '10년이하'\n",
    "        elif row <= 25:\n",
    "            return '25년이하'\n",
    "        elif row > 25:\n",
    "            return '25년초과'\n",
    "        else:\n",
    "            return row\n",
    "    \n",
    "    # 연차를 성장단계로 범주화\n",
    "    df['성장단계'] = df['연차'].apply(convert_years).apply(convert_years_2)\n",
    "    \n",
    "    def convert_add(row):\n",
    "        if pd.isnull(row):\n",
    "            return np.nan\n",
    "        elif row in ['서울', '인천', '경기']:\n",
    "            return '수도권'\n",
    "        else:\n",
    "            return '비수도권'\n",
    "    \n",
    "    # 주소를 수도권/비수도권으로 범주화\n",
    "    df['주소'] = df['주소1'].apply(convert_add)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_financial_data(comp_finance):\n",
    "    \"\"\"\n",
    "    재무 정보를 전처리하고 결측치가 많은 칼럼을 삭제하며 이상치를 처리합니다.\n",
    "    \"\"\"\n",
    "    # 재무 데이터를 피벗 테이블 형태로 변환\n",
    "    comp_finance_final = comp_finance.pivot_table(index=['BusinessNum', 'stYear'], columns='accNm', values='acctAmt').reset_index()\n",
    "    \n",
    "    # 결측치 비율이 30% 이상인 열 삭제\n",
    "    threshold = 0.3\n",
    "    comp_finance_final_2 = comp_finance_final.loc[:, comp_finance_final.isnull().mean() < threshold]\n",
    "    \n",
    "    def replace_outliers_with_bounds(df, column):\n",
    "        \"\"\"\n",
    "        IQR 방식을 사용하여 이상치를 상한값/하한값으로 치환\n",
    "        \"\"\"\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df.loc[df[column] > upper_bound, column] = upper_bound\n",
    "        df.loc[df[column] < lower_bound, column] = lower_bound\n",
    "        return df\n",
    "    \n",
    "    # 각 컬럼에 대해 이상치 처리\n",
    "    for column in comp_finance_final_2.columns:\n",
    "        comp_finance_final_2 = replace_outliers_with_bounds(comp_finance_final_2, column)\n",
    "    \n",
    "    return comp_finance_final_2\n",
    "\n",
    "def train_and_predict(df_all, df_predict_ex):\n",
    "    \"\"\"\n",
    "    모델을 학습시키고 2022년 예측값을 생성합니다.\n",
    "    \"\"\"\n",
    "    # 불필요한 컬럼 제거\n",
    "    df_all.drop(columns=['BusinessNum', 'stYear'], inplace=True)\n",
    "    df_all = df_all.dropna(subset=['매출액', '영업이익', '당기순이익(손실)'])\n",
    "    df_predict_ex.drop(columns=['stYear'], inplace=True)\n",
    "    \n",
    "    # 카테고리와 숫자형 변수 리스트 생성\n",
    "    category_list = df_all.select_dtypes(include=['object']).columns\n",
    "    numeric_list = df_all.select_dtypes(include=[np.number]).columns.drop(['매출액', '영업이익', '당기순이익(손실)'])\n",
    "    \n",
    "    # 전처리 파이프라인 정의\n",
    "    numeric_pipe = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n",
    "    category_pipe = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown='ignore'))\n",
    "    prepro_pipe = make_column_transformer((numeric_pipe, numeric_list), (category_pipe, category_list))\n",
    "    \n",
    "    # 학습 데이터 전처리\n",
    "    X = df_all.drop(columns=['매출액', '영업이익', '당기순이익(손실)'])\n",
    "    prepro_pipe.fit(X)\n",
    "    X_transformed = prepro_pipe.transform(X)\n",
    "    \n",
    "    # 예측 데이터 전처리\n",
    "    X_new = df_predict_ex.drop(columns=['BusinessNum'])\n",
    "    X_new_transformed = prepro_pipe.transform(X_new)\n",
    "    \n",
    "    # 예측 대상 변수 목록\n",
    "    targets = ['매출액', '영업이익', '당기순이익(손실)']\n",
    "    predictions = df_predict_ex[['BusinessNum']].copy()\n",
    "    \n",
    "    for target in targets:\n",
    "        Y = df_all[target]\n",
    "        \n",
    "        # 학습 데이터와 테스트 데이터 분리\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_transformed, Y, random_state=42)\n",
    "        \n",
    "        # 모델 정의 및 학습\n",
    "        model = xgb.XGBRegressor()\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        # 예측값 저장\n",
    "        predictions[target] = model.predict(X_new_transformed)\n",
    "    \n",
    "    # 예측 결과 저장\n",
    "    predictions.to_csv('(2024_bigdata)2022_predict_1조.csv', index=False)\n",
    "\n",
    "def prediction_2022():\n",
    "    \"\"\"\n",
    "    전체 예측 과정을 실행하는 메인 함수\n",
    "    \"\"\"\n",
    "    # 데이터 로드\n",
    "    comp_finance, comp_intro, mapping, df_industry, df_predict_ex = load_data()\n",
    "    \n",
    "    # 산업분류코드 전처리\n",
    "    df_industry_unique = preprocess_industry(df_industry)\n",
    "    \n",
    "    # 기업정보 전처리\n",
    "    comp_intro_m1 = preprocess_comp_intro(comp_intro, df_industry_unique)\n",
    "    \n",
    "    # 세부 기업정보 전처리\n",
    "    df2 = preprocess_comp_intro_details(comp_intro_m1, mapping)\n",
    "    \n",
    "    # 종업원수 결측치 보완 및 이상치 제거\n",
    "    df4 = fill_missing_employee_counts(df2, comp_finance)\n",
    "    \n",
    "    # 연차와 주소 범주화\n",
    "    comp_intro_m2 = categorize_data(df4)\n",
    "    \n",
    "    # 재무정보 전처리\n",
    "    comp_finance_final = preprocess_financial_data(comp_finance)\n",
    "    \n",
    "    # 전처리된 데이터 병합\n",
    "    df_all = pd.merge(comp_intro_m2, comp_finance_final, on='BusinessNum', how='inner')\n",
    "    \n",
    "    # 모델 학습 및 예측\n",
    "    train_and_predict(df_all, df_predict_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929a4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
